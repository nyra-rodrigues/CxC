{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records AFTER Removing 'None': 325900\n",
      "Total records in First 28 Days: 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/1950187504.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['previous_event_type'].fillna(\"None\", inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/1950187504.py:89: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['time_since_previous_event'].fillna(0, inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/1950187504.py:90: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['session_event_count'].fillna(1, inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/1950187504.py:112: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['time_since_last_session'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "file_path = '2024combined_file.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['server_received_time'] = pd.to_datetime(df['server_received_time'])\n",
    "df = df.sort_values(by=['user_id', 'server_received_time'])\n",
    "\n",
    "df['time_since_last'] = df.groupby('user_id')['server_received_time'].diff()\n",
    "df['is_new_session'] = df['time_since_last'].isna() | (df['time_since_last'] > pd.Timedelta(minutes=30))\n",
    "df['session_id'] = df.groupby('user_id')['is_new_session'].cumsum().astype(str) + \"_\" + df['user_id']\n",
    "df = df.sort_values(by=['session_id', 'server_received_time'])\n",
    "\n",
    "df['next_session_time'] = df.groupby('user_id')['server_received_time'].shift(-1)\n",
    "df['returned'] = (df['next_session_time'] - df['server_received_time']) > pd.Timedelta(days=1)\n",
    "retention_rates = df.groupby('event_type')['returned'].mean().reset_index()\n",
    "retention_rates.columns = ['event_type', 'retention_probability']\n",
    "df = df.merge(retention_rates, on='event_type', how='left')\n",
    "\n",
    "df['next_action'] = df.groupby('session_id')['event_type'].shift(-1)\n",
    "df = df.merge(retention_rates, left_on='next_action', right_on='event_type', how='left', suffixes=('', '_next'))\n",
    "df['y_best'] = df.groupby('event_type')['event_type_next'].transform(\n",
    "    lambda x: x.mode()[0] if not x.isna().all() else \"session_end\"\n",
    ")\n",
    "df = df[['session_id', 'user_id', 'server_received_time', 'event_type', 'event_properties', 'y_best']]\n",
    "df['y_best'] = df['y_best'].fillna(\"session_end\")\n",
    "df = df.sort_values(by=['session_id', 'server_received_time'])\n",
    "\n",
    "def extract_property(event_json, key):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(event_json)\n",
    "        return parsed.get(key, None)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "df['event_slug'] = df['event_properties'].apply(lambda x: extract_property(x, 'slug'))\n",
    "df['event_display_name'] = df['event_properties'].apply(lambda x: extract_property(x, 'displayName'))\n",
    "df['y_best_detail'] = df.groupby('session_id')['event_slug'].shift(-1)\n",
    "df['y_best_display'] = df.groupby('session_id')['event_display_name'].shift(-1)\n",
    "df['y_best'] = df['y_best'].astype(str) + \"::\" + df['y_best_detail'].astype(str)\n",
    "df['y_best'] = df['y_best'].fillna(df['event_type'])\n",
    "\n",
    "generic_actions = [\"application-window-opened\", \"session_start\", \"session_end\", \"::None\"]\n",
    "df = df[~df['y_best'].isin(generic_actions)]\n",
    "df = df[~df['y_best'].str.endswith(\"::None\")]\n",
    "df = df[~df['y_best'].str.endswith(\"widget:render\")]\n",
    "df = df[~df['y_best'].str.endswith(\"widget:render::None\")]\n",
    "df.loc[df['event_type'] == df['y_best'], 'y_best'] = \"session_end\"\n",
    "df['y_best'] = df['y_best'].str.replace(\"::nan\", \"\", regex=False)\n",
    "\n",
    "df[['primary_y', 'detail_y']] = df['y_best'].str.split(\"::\", n=1, expand=True)\n",
    "df['detail_y'] = df['detail_y'].fillna(\"None\")\n",
    "\n",
    "df = df[df['detail_y'] != \"None\"]\n",
    "\n",
    "df['session_length'] = df.groupby('session_id')['server_received_time'].transform(\n",
    "    lambda x: (x.max() - x.min()).total_seconds()\n",
    ")\n",
    "df['time_since_last_session'] = df.groupby('user_id')['server_received_time'].diff().dt.total_seconds()\n",
    "df['total_past_sessions'] = df.groupby('user_id')['session_id'].transform('nunique')\n",
    "\n",
    "df['event_category'] = df['event_type'].apply(lambda x: x.split(\":\")[1] if \":\" in x else x)\n",
    "df['hour_of_day'] = df['server_received_time'].dt.hour\n",
    "df['day_of_week'] = df['server_received_time'].dt.dayofweek  \n",
    "df['is_working_hours'] = df['hour_of_day'].apply(lambda x: 1 if 9 <= x <= 18 else 0)\n",
    "\n",
    "df['server_received_time_numeric'] = df['server_received_time'].astype(np.int64) // 10**9\n",
    "\n",
    "df['previous_event_type'] = df.groupby('session_id')['event_type'].shift(1)\n",
    "df['time_since_previous_event'] = df.groupby('session_id')['server_received_time_numeric'].diff()\n",
    "df['session_event_count'] = df.groupby('session_id')['event_type'].transform('count')\n",
    "\n",
    "df['previous_event_type'].fillna(\"None\", inplace=True)\n",
    "df['time_since_previous_event'].fillna(0, inplace=True)\n",
    "df['session_event_count'].fillna(1, inplace=True)\n",
    "\n",
    "df = df[['session_id'] + list(df.columns.difference(['session_id']))] \n",
    "\n",
    "start_date = pd.to_datetime(df['server_received_time_numeric'].min(), unit='s')\n",
    "cutoff_date = start_date + pd.Timedelta(days=28)\n",
    "cutoff_numeric = int(cutoff_date.timestamp())\n",
    "df_first_28 = df[df['server_received_time_numeric'] < cutoff_numeric]\n",
    "\n",
    "features = [\n",
    "    'session_length', 'time_since_last_session', 'total_past_sessions',\n",
    "    'event_type', 'event_category', 'event_slug', 'event_display_name',\n",
    "    'hour_of_day', 'day_of_week', 'is_working_hours', 'server_received_time_numeric',\n",
    "    'previous_event_type', 'time_since_previous_event', 'session_event_count'  \n",
    "]\n",
    "target = 'y_best'\n",
    "df = df[features + [target]]\n",
    "\n",
    "df['time_since_last_session'].fillna(0, inplace=True)\n",
    "df.loc[df['session_length'] == 0, 'session_length'] = 1\n",
    "df['total_past_sessions'] = df['total_past_sessions'].fillna(0).astype(int)\n",
    "\n",
    "print(\"Total records AFTER Removing 'None':\", len(df))\n",
    "print(\"Total records in First 28 Days:\", len(df_first_28))\n",
    "\n",
    "X_prepared = df_first_28[features]\n",
    "y_prepared = df_first_28[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if session_id exists: True\n",
      "Columns in df_first_28: Index(['session_id', 'day_of_week', 'detail_y', 'event_category',\n",
      "       'event_display_name', 'event_properties', 'event_slug', 'event_type',\n",
      "       'hour_of_day', 'is_working_hours', 'previous_event_type', 'primary_y',\n",
      "       'server_received_time', 'server_received_time_numeric',\n",
      "       'session_event_count', 'session_length', 'time_since_last_session',\n",
      "       'time_since_previous_event', 'total_past_sessions', 'user_id', 'y_best',\n",
      "       'y_best_detail', 'y_best_display'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/2121873437.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_first_28['previous_event_type'].fillna(\"None\", inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/2121873437.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_first_28['time_since_previous_event'].fillna(0, inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/2121873437.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with timedelta64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df_first_28['time_since_previous_event'].fillna(0, inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/2121873437.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_first_28['time_since_previous_event'].fillna(0, inplace=True)\n",
      "/var/folders/hc/wd_ljd853ps_jsfw722n74d80000gn/T/ipykernel_54944/2121873437.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_first_28['session_event_count'].fillna(1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_first_28 = df_first_28[['session_id'] + list(df_first_28.columns.difference(['session_id']))]\n",
    "\n",
    "df_first_28[['primary_y', 'detail_y']] = df_first_28['y_best'].str.split(\"::\", n=1, expand=True)\n",
    "df_first_28['detail_y'] = df_first_28['detail_y'].fillna(\"None\")\n",
    "\n",
    "df_first_28 = df_first_28[df_first_28['detail_y'] != \"None\"]\n",
    "\n",
    "if 'session_id' not in df_first_28.columns:\n",
    "    raise KeyError(\"Error: session_id is missing before computing contextual features!\")\n",
    "\n",
    "print(\"Checking if session_id exists:\", 'session_id' in df_first_28.columns)\n",
    "\n",
    "df_first_28['previous_event_type'] = df_first_28.groupby('session_id')['event_type'].shift(1)\n",
    "df_first_28['time_since_previous_event'] = df_first_28.groupby('session_id')['server_received_time'].diff()\n",
    "df_first_28['session_event_count'] = df_first_28.groupby('session_id')['event_type'].transform('count')\n",
    "\n",
    "df_first_28['previous_event_type'].fillna(\"None\", inplace=True)\n",
    "df_first_28['time_since_previous_event'].fillna(0, inplace=True)\n",
    "df_first_28['session_event_count'].fillna(1, inplace=True)\n",
    "\n",
    "print(\"Columns in df_first_28:\", df_first_28.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (231, 11)\n",
      "y_primary_train shape: (231,)\n",
      "y_detail_train shape: (231,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = [\n",
    "    'session_length', 'time_since_last_session', 'total_past_sessions',\n",
    "    'event_type', 'event_category', 'event_slug', 'event_display_name',\n",
    "    'hour_of_day', 'day_of_week', 'is_working_hours', 'server_received_time_numeric'\n",
    "]\n",
    "\n",
    "X = df_first_28[features]\n",
    "y_primary = df_first_28['primary_y']\n",
    "y_detail = df_first_28['detail_y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_primary_train, y_primary_val = train_test_split(X, y_primary, test_size=0.2, random_state=42)\n",
    "y_detail_train = y_detail.loc[X_train.index]  \n",
    "y_detail_val = y_detail.loc[X_val.index]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_primary_train shape:\", y_primary_train.shape)\n",
    "print(\"y_detail_train shape:\", y_detail_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transformed shape: (231, 56)\n",
      "X_val_transformed shape: (58, 56)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = [\n",
    "    'session_length', 'time_since_last_session', 'total_past_sessions',\n",
    "    'hour_of_day', 'day_of_week', 'is_working_hours', 'server_received_time_numeric'\n",
    "]\n",
    "categorical_features = ['event_type', 'event_category', 'event_slug', 'event_display_name']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "print(\"X_train_transformed shape:\", X_train_transformed.shape)\n",
    "print(\"X_val_transformed shape:\", X_val_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Model Training Accuracy: 1.0\n",
      "Primary Model Validation Accuracy: 0.9310344827586207\n",
      "\n",
      "Primary Model Classification Report:\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                                             1.00      0.80      0.89         5\n",
      "                               account       1.00      0.88      0.94        17\n",
      "                         account-lines       0.87      1.00      0.93        13\n",
      "account-property-rating:pricing-detail       0.00      0.00      0.00         1\n",
      "                         action-center       0.50      1.00      0.67         2\n",
      "          action-center:action-details       1.00      1.00      1.00         1\n",
      "                      agency-dashboard       1.00      1.00      1.00         2\n",
      "                          all-accounts       1.00      1.00      1.00         2\n",
      "                     dashboard:my-book       1.00      1.00      1.00        12\n",
      "         submissions:policy-definition       1.00      1.00      1.00         3\n",
      "\n",
      "                              accuracy                           0.93        58\n",
      "                             macro avg       0.84      0.87      0.84        58\n",
      "                          weighted avg       0.94      0.93      0.93        58\n",
      "\n",
      "Detail Model Training Accuracy: 1.0\n",
      "Detail Model Validation Accuracy: 0.43103448275862066\n",
      "\n",
      "Detail Model Classification Report:\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                              :action-click       0.00      0.00      0.00         1\n",
      "                       :change-rating-click       0.00      0.00      0.00         0\n",
      "                               :close-click       0.67      1.00      0.80         2\n",
      "                                      :view       1.00      0.48      0.65        25\n",
      "               accounts-table:account-click       0.67      1.00      0.80         2\n",
      "                   advanced-filters-applied       0.00      0.00      0.00         0\n",
      "documents-and-compliance-accordion:selected       0.00      0.00      0.00         2\n",
      "            drivers-info-accordion:selected       0.00      0.00      0.00         1\n",
      "           loss-analysis-accordion:selected       0.00      0.00      0.00         1\n",
      "                  losses-accordion:selected       0.11      1.00      0.20         1\n",
      "             nav-header:action-center-click       0.00      0.00      0.00         5\n",
      "                         open-ra-file-click       0.00      0.00      0.00         1\n",
      "              operations-accordion:selected       0.00      0.00      0.00         0\n",
      "        related-entities-accordion:selected       0.00      0.00      0.00         0\n",
      "             safety-info-accordion:selected       0.00      0.00      0.00         0\n",
      "                               submit-click       1.00      1.00      1.00         3\n",
      "       templeton-docs:create-document-click       0.00      0.00      0.00         0\n",
      "                                       view       0.80      0.31      0.44        13\n",
      "                              widget:render       1.00      1.00      1.00         1\n",
      "\n",
      "                                   accuracy                           0.43        58\n",
      "                                  macro avg       0.28      0.30      0.26        58\n",
      "                               weighted avg       0.73      0.43      0.51        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arpitsrivastav/miniconda3/envs/spyder-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_balanced, y_detail_train_balanced = undersampler.fit_resample(X_train_transformed, y_detail_train)\n",
    "\n",
    "\n",
    "primary_pipeline = Pipeline(steps=[\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "detail_pipeline = Pipeline(steps=[\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "primary_pipeline.fit(X_train_transformed, y_primary_train)\n",
    "detail_pipeline.fit(X_train_balanced, y_detail_train_balanced)\n",
    "\n",
    "y_primary_pred = primary_pipeline.predict(X_val_transformed)\n",
    "y_detail_pred = detail_pipeline.predict(X_val_transformed)\n",
    "\n",
    "print(\"Primary Model Training Accuracy:\", primary_pipeline.score(X_train_transformed, y_primary_train))\n",
    "print(\"Primary Model Validation Accuracy:\", accuracy_score(y_primary_val, y_primary_pred))\n",
    "print(\"\\nPrimary Model Classification Report:\")\n",
    "print(classification_report(y_primary_val, y_primary_pred))\n",
    "\n",
    "print(\"Detail Model Training Accuracy:\", detail_pipeline.score(X_train_balanced, y_detail_train_balanced))\n",
    "print(\"Detail Model Validation Accuracy:\", accuracy_score(y_detail_val, y_detail_pred))\n",
    "print(\"\\nDetail Model Classification Report:\")\n",
    "print(classification_report(y_detail_val, y_detail_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Primary: account-lines\n",
      "Predicted Detail: :change-rating-click\n",
      "Final Hierarchical Prediction: account-lines:::change-rating-click\n"
     ]
    }
   ],
   "source": [
    "# Scenario: User is viewing an account summary\n",
    "sample_input_1 = {\n",
    "    'session_length': 400,                # Session lasted ~6.7 minutes\n",
    "    'time_since_last_session': 180,       # 3 minutes since last session\n",
    "    'total_past_sessions': 15,            # User has had 15 sessions\n",
    "    'event_type': 'account-lines::account-summary:view',  \n",
    "    'event_category': 'account-lines',    \n",
    "    'event_slug': 'account-overview',     # Viewing account details\n",
    "    'event_display_name': 'view',        \n",
    "    'hour_of_day': 10,                    # 10 AM\n",
    "    'day_of_week': 3,                      # Wednesday (assuming Monday is 0)\n",
    "    'is_working_hours': 1,                 # Within working hours\n",
    "    'server_received_time_numeric': 1714750000  \n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df_1 = pd.DataFrame([sample_input_1])\n",
    "\n",
    "# Apply preprocessing to match training format\n",
    "sample_df_transformed_1 = preprocessor.transform(sample_df_1)\n",
    "\n",
    "# Predict primary and detail components\n",
    "pred_primary_1 = primary_pipeline.predict(sample_df_transformed_1)\n",
    "pred_detail_1 = detail_pipeline.predict(sample_df_transformed_1)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted Primary:\", pred_primary_1[0])\n",
    "print(\"Predicted Detail:\", pred_detail_1[0])\n",
    "\n",
    "# Combine predictions\n",
    "hierarchical_prediction_1 = pred_primary_1[0] + \"::\" + pred_detail_1[0]\n",
    "print(\"Final Hierarchical Prediction:\", hierarchical_prediction_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Primary: account-lines\n",
      "Predicted Detail: advanced-filters-applied\n",
      "Final Hierarchical Prediction: account-lines::advanced-filters-applied\n"
     ]
    }
   ],
   "source": [
    "# Scenario: User is opening a dashboard policy table\n",
    "sample_input_2 = {\n",
    "    'session_length': 500,                \n",
    "    'time_since_last_session': 240,       \n",
    "    'total_past_sessions': 22,            \n",
    "    'event_type': 'dashboard:policy-table:render',  \n",
    "    'event_category': 'dashboard',        \n",
    "    'event_slug': 'policy-table',         \n",
    "    'event_display_name': 'render',       \n",
    "    'hour_of_day': 13,                    \n",
    "    'day_of_week': 4,                      \n",
    "    'is_working_hours': 1,                 \n",
    "    'server_received_time_numeric': 1714800000  \n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df_2 = pd.DataFrame([sample_input_2])\n",
    "\n",
    "# Apply preprocessing\n",
    "sample_df_transformed_2 = preprocessor.transform(sample_df_2)\n",
    "\n",
    "# Predict primary and detail components\n",
    "pred_primary_2 = primary_pipeline.predict(sample_df_transformed_2)\n",
    "pred_detail_2 = detail_pipeline.predict(sample_df_transformed_2)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted Primary:\", pred_primary_2[0])\n",
    "print(\"Predicted Detail:\", pred_detail_2[0])\n",
    "\n",
    "# Combine predictions\n",
    "hierarchical_prediction_2 = pred_primary_2[0] + \"::\" + pred_detail_2[0]\n",
    "print(\"Final Hierarchical Prediction:\", hierarchical_prediction_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Primary: account-lines\n",
      "Predicted Detail: :change-rating-click\n",
      "Final Hierarchical Prediction: account-lines:::change-rating-click\n"
     ]
    }
   ],
   "source": [
    "# Scenario: User clicks on submission risk insights widget\n",
    "sample_input_3 = {\n",
    "    'session_length': 450,                \n",
    "    'time_since_last_session': 210,       \n",
    "    'total_past_sessions': 18,            \n",
    "    'event_type': 'submission:risk-insights:click',  \n",
    "    'event_category': 'submission',       \n",
    "    'event_slug': 'risk-dashboard',       \n",
    "    'event_display_name': 'click',        \n",
    "    'hour_of_day': 16,                    \n",
    "    'day_of_week': 2,                      \n",
    "    'is_working_hours': 1,                 \n",
    "    'server_received_time_numeric': 1714900000  \n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df_3 = pd.DataFrame([sample_input_3])\n",
    "\n",
    "# Apply preprocessing\n",
    "sample_df_transformed_3 = preprocessor.transform(sample_df_3)\n",
    "\n",
    "# Predict primary and detail components\n",
    "pred_primary_3 = primary_pipeline.predict(sample_df_transformed_3)\n",
    "pred_detail_3 = detail_pipeline.predict(sample_df_transformed_3)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted Primary:\", pred_primary_3[0])\n",
    "print(\"Predicted Detail:\", pred_detail_3[0])\n",
    "\n",
    "# Combine predictions\n",
    "hierarchical_prediction_3 = pred_primary_3[0] + \"::\" + pred_detail_3[0]\n",
    "print(\"Final Hierarchical Prediction:\", hierarchical_prediction_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Primary: account-lines\n",
      "Predicted Detail: advanced-filters-applied\n",
      "Final Hierarchical Prediction: account-lines::advanced-filters-applied\n"
     ]
    }
   ],
   "source": [
    "# Scenario: User is downloading a compliance report from account lines\n",
    "sample_input_7 = {\n",
    "    'session_length': 300,                \n",
    "    'time_since_last_session': 100,       \n",
    "    'total_past_sessions': 20,            \n",
    "    'event_type': 'account-lines:compliance:download',  \n",
    "    'event_category': 'account-lines',    \n",
    "    'event_slug': 'compliance-report',    \n",
    "    'event_display_name': 'download',     \n",
    "    'hour_of_day': 15,                    \n",
    "    'day_of_week': 5,                      \n",
    "    'is_working_hours': 1,                 \n",
    "    'server_received_time_numeric': 1715300000  \n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df_7 = pd.DataFrame([sample_input_7])\n",
    "\n",
    "# Apply preprocessing\n",
    "sample_df_transformed_7 = preprocessor.transform(sample_df_7)\n",
    "\n",
    "# Predict primary and detail components\n",
    "pred_primary_7 = primary_pipeline.predict(sample_df_transformed_7)\n",
    "pred_detail_7 = detail_pipeline.predict(sample_df_transformed_7)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted Primary:\", pred_primary_7[0])\n",
    "print(\"Predicted Detail:\", pred_detail_7[0])\n",
    "\n",
    "# Combine predictions\n",
    "hierarchical_prediction_7 = pred_primary_7[0] + \"::\" + pred_detail_7[0]\n",
    "print(\"Final Hierarchical Prediction:\", hierarchical_prediction_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Input Prediction Primary: dashboard:my-book\n",
      "Fixed Input Prediction Detail: advanced-filters-applied\n",
      "Final Fixed Prediction: dashboard:my-book::advanced-filters-applied\n"
     ]
    }
   ],
   "source": [
    "real_event_type = X_train['event_type'].sample(1).values[0]  # Select a real event type\n",
    "real_event_category = X_train['event_category'].sample(1).values[0]  # Select a real category\n",
    "\n",
    "sample_input_fixed = {\n",
    "    'session_length': 500,\n",
    "    'time_since_last_session': 240,\n",
    "    'total_past_sessions': 22,\n",
    "    'event_type': real_event_type,  \n",
    "    'event_category': real_event_category, \n",
    "    'event_slug': 'policy-table', \n",
    "    'event_display_name': 'render',\n",
    "    'hour_of_day': 13,\n",
    "    'day_of_week': 4,\n",
    "    'is_working_hours': 1,\n",
    "    'server_received_time_numeric': 1714800000  \n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_df_fixed = pd.DataFrame([sample_input_fixed])\n",
    "\n",
    "# Apply preprocessing\n",
    "sample_df_transformed_fixed = preprocessor.transform(sample_df_fixed)\n",
    "\n",
    "# Predict primary and detail components\n",
    "pred_primary_fixed = primary_pipeline.predict(sample_df_transformed_fixed)\n",
    "pred_detail_fixed = detail_pipeline.predict(sample_df_transformed_fixed)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Fixed Input Prediction Primary:\", pred_primary_fixed[0])\n",
    "print(\"Fixed Input Prediction Detail:\", pred_detail_fixed[0])\n",
    "print(\"Final Fixed Prediction:\", pred_primary_fixed[0] + \"::\" + pred_detail_fixed[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real Sample 1 Prediction:\n",
      "Primary: dashboard:my-book\n",
      "Detail: view\n",
      "Final Prediction: dashboard:my-book::view\n",
      "\n",
      "Real Sample 2 Prediction:\n",
      "Primary: dashboard:my-book\n",
      "Detail: :change-rating-click\n",
      "Final Prediction: dashboard:my-book:::change-rating-click\n",
      "\n",
      "Real Sample 3 Prediction:\n",
      "Primary: goals-and-rules:rules\n",
      "Detail: :change-rating-click\n",
      "Final Prediction: goals-and-rules:rules:::change-rating-click\n"
     ]
    }
   ],
   "source": [
    "real_sample = X_train.sample(3)\n",
    "real_sample_transformed = preprocessor.transform(real_sample)\n",
    "pred_primary_real = primary_pipeline.predict(real_sample_transformed)\n",
    "pred_detail_real = detail_pipeline.predict(real_sample_transformed)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\nReal Sample {i+1} Prediction:\")\n",
    "    print(\"Primary:\", pred_primary_real[i])\n",
    "    print(\"Detail:\", pred_detail_real[i])\n",
    "    print(\"Final Prediction:\", pred_primary_real[i] + \"::\" + pred_detail_real[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
